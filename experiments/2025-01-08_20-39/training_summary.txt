GLOBALS

# DATASET
Positives_csv = './datasets/AudioSet_EV/EV_Positives.csv'
Positives = "./datasets/AudioSet_EV/Positive_files/"
Negatives_csv = './datasets/AudioSet_EV/EV_Negatives.csv'
Negatives = "./datasets/AudioSet_EV/Negative_files/"

# MODEL PARAMETERS
batch_size = 32
threshold = 0.5
output_mode = "bin_raw"
learning_rate = 1e-3
weight_decay = 1e-6
t_max = 10
eta_min = 1e-6

# TRAINING CONSTANTS
overall_training = True
EPOCHS = 100
PATIENCE = 33
CHECKPOINT_DIR = "./experiments/checkpoints"    # Created by the Lightning Trainer (init)
RESULTS_DIR = "./experiments/model_results"     # Created by the Lightning Model (init)
----------------------------------------------------------------------------------------------------------------------------------------------------


CONSOLE OUTPUTS

Seed set to 42
Logs will be saved in:  ./experiments/tb_logs/EPANNs_Binarized/version_0
Starting TensorBoard at log directory: ./experiments/tb_logs/EPANNs_Binarized/version_0
--------------------------------------------------------------------------


TensorFlow installation not found - running with reduced feature set.

NOTE: Using experimental fast data loading logic. To disable, pass
    "--load_fast=false" and report issues on GitHub. More details:
    https://github.com/tensorflow/tensorboard/issues/4784

TensorBoard 2.18.0 at http://0.0.0.0:6010/ (Press CTRL+C to quit)
--2025-01-08 20:39:18--  https://github.com/StefanoGiacomelli/epanns_inference/raw/main/epanns_inference/models/checkpoint_closeto_.44.pt
Risoluzione di github.com (github.com)... 140.82.121.4
Connessione a github.com (github.com)|140.82.121.4|:443... connesso.
Richiesta HTTP inviata, in attesa di risposta... 302 Found
Posizione: https://raw.githubusercontent.com/StefanoGiacomelli/epanns_inference/main/epanns_inference/models/checkpoint_closeto_.44.pt [segue]
--2025-01-08 20:39:18--  https://raw.githubusercontent.com/StefanoGiacomelli/epanns_inference/main/epanns_inference/models/checkpoint_closeto_.44.pt
Risoluzione di raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...
Connessione a raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connesso.
Richiesta HTTP inviata, in attesa di risposta... 200 OK
Lunghezza: 97207494 (93M) [application/octet-stream]
Salvataggio in: «./checkpoint_closeto_.44.pt»

./checkpoint_closeto_.44.pt                     100%[=====================================================================================================>]  92,70M  21,3MB/s    in 4,2s    

2025-01-08 20:39:26 (22,1 MB/s) - «./checkpoint_closeto_.44.pt» salvato [97207494/97207494]

/home/user/Documenti/e2panns/.venv/lib/python3.11/site-packages/epanns_inference/models/models.py:191: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load('./checkpoint_closeto_.44.pt', map_location=lambda storage, loc: storage)
--------------------------------------------------------------------------


GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Training Model...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name                  | Type                   | Params | Mode 
--------------------------------------------------------------------------
0  | model                 | Cnn14_pruned           | 24.3 M | train
1  | criterion             | BCELoss                | 0      | train
2  | train_accuracy        | BinaryAccuracy         | 0      | train
3  | val_accuracy          | BinaryAccuracy         | 0      | train
4  | val_precision         | BinaryPrecision        | 0      | train
5  | val_recall            | BinaryRecall           | 0      | train
6  | val_f1                | BinaryF1Score          | 0      | train
7  | test_accuracy         | BinaryAccuracy         | 0      | train
8  | test_confusion_matrix | BinaryConfusionMatrix  | 0      | train
9  | test_precision        | BinaryPrecision        | 0      | train
10 | test_recall           | BinaryRecall           | 0      | train
11 | test_f1               | BinaryF1Score          | 0      | train
12 | test_specificity      | BinarySpecificity      | 0      | train
13 | test_auroc            | BinaryAUROC            | 0      | train
14 | test_auprc            | BinaryAveragePrecision | 0      | train
15 | test_mcc              | BinaryMatthewsCorrCoef | 0      | train
16 | test_fbeta            | BinaryFBetaScore       | 0      | train
17 | test_stat_scores      | BinaryStatScores       | 0      | train
--------------------------------------------------------------------------
23.2 M    Trainable params
1.1 M     Non-trainable params
24.3 M    Total params
97.157    Total estimated model params size (MB)
59        Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                                                                                     | 0/2 [00:00<?, ?it/s]/home/user/Documenti/e2panns/.venv/lib/python3.11/site-packages/epanns_inference/models/models.py:241: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  clipwise_output = nn.functional.softmax(self.fc_audioset(x))
Epoch 0: 100%|█| 351/351 [01:00<00:00,  5.77it/s, v_num=0, train_loss_step=0.611, train_accuracy_step=0.650, val_loss=0.360, epoch_val_accuracy=0.849, epoch_val_precision=0.934, epoch_val_reMetric epoch_val_accuracy improved. New best score: 0.849                                                                                                                                     
Epoch 0, global step 351: 'epoch_val_accuracy' reached 0.84879 (best 0.84879), saving model to '/home/user/Documenti/e2panns/experiments/checkpoints/epoch=0_epoch_val_accuracy=0.8488.ckpt' as top 1
Epoch 1:   5%| | 19/351 [00:03<00:56,  5.91it/s, v_num=0, train_loss_step=0.285, train_accuracy_step=0.875, val_loss=0.360, epoch_val_accuracy=0.849, epoch                                   Epoch 1: 100%|█| 351/351 [01:01<00:00,  5.75it/s, v_num=0, train_loss_step=0.328, train_accuracy_step=0.750, val_loss=0.346, epoch_val_accuracy=0.845, epoch_val_precision=0.903, epoch_val_reEpoch 1, global step 702: 'epoch_val_accuracy' was not in top 1                                                                                                                               
Epoch 2: 100%|█| 351/351 [01:00<00:00,  5.77it/s, v_num=0, train_loss_step=0.183, train_accuracy_step=1.000, val_loss=0.350, epoch_val_accuracy=0.850, epoch_val_precision=0.926, epoch_val_reMetric epoch_val_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.850                                                                                                         
Epoch 2, global step 1053: 'epoch_val_accuracy' reached 0.84950 (best 0.84950), saving model to '/home/user/Documenti/e2panns/experiments/checkpoints/epoch=2_epoch_val_accuracy=0.8495.ckpt' as top 1
Epoch 3: 100%|█| 351/351 [01:01<00:00,  5.74it/s, v_num=0, train_loss_step=0.265, train_accuracy_step=0.850, val_loss=0.346, epoch_val_accuracy=0.860, epoch_val_precision=0.946, epoch_val_reMetric epoch_val_accuracy improved by 0.011 >= min_delta = 0.0. New best score: 0.860                                                                                                         
Epoch 3, global step 1404: 'epoch_val_accuracy' reached 0.86020 (best 0.86020), saving model to '/home/user/Documenti/e2panns/experiments/checkpoints/epoch=3_epoch_val_accuracy=0.8602.ckpt' as top 1
Epoch 4: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.142, train_accuracy_step=0.950, val_loss=0.347, epoch_val_accuracy=0.852, epoch_val_precision=0.872, epoch_val_reEpoch 4, global step 1755: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 5: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.325, train_accuracy_step=0.850, val_loss=0.342, epoch_val_accuracy=0.858, epoch_val_precision=0.908, epoch_val_reEpoch 5, global step 2106: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 6: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.0444, train_accuracy_step=1.000, val_loss=0.350, epoch_val_accuracy=0.840, epoch_val_precision=0.881, epoch_val_rEpoch 6, global step 2457: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 7: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.280, train_accuracy_step=0.900, val_loss=0.353, epoch_val_accuracy=0.850, epoch_val_precision=0.888, epoch_val_reEpoch 7, global step 2808: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 8: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.137, train_accuracy_step=0.950, val_loss=0.362, epoch_val_accuracy=0.851, epoch_val_precision=0.869, epoch_val_reEpoch 8, global step 3159: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 9: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.166, train_accuracy_step=0.900, val_loss=0.366, epoch_val_accuracy=0.850, epoch_val_precision=0.870, epoch_val_reEpoch 9, global step 3510: 'epoch_val_accuracy' was not in top 1                                                                                                                              
Epoch 10: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.241, train_accuracy_step=0.800, val_loss=0.365, epoch_val_accuracy=0.850, epoch_val_precision=0.867, epoch_val_rEpoch 10, global step 3861: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 11: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.284, train_accuracy_step=0.750, val_loss=0.360, epoch_val_accuracy=0.855, epoch_val_precision=0.885, epoch_val_rEpoch 11, global step 4212: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 12: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.127, train_accuracy_step=1.000, val_loss=0.369, epoch_val_accuracy=0.847, epoch_val_precision=0.864, epoch_val_rEpoch 12, global step 4563: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 13: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.448, train_accuracy_step=0.750, val_loss=0.381, epoch_val_accuracy=0.848, epoch_val_precision=0.874, epoch_val_rEpoch 13, global step 4914: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 14: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.207, train_accuracy_step=0.950, val_loss=0.400, epoch_val_accuracy=0.817, epoch_val_precision=0.803, epoch_val_rEpoch 14, global step 5265: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 15: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.354, train_accuracy_step=0.850, val_loss=0.389, epoch_val_accuracy=0.836, epoch_val_precision=0.854, epoch_val_rEpoch 15, global step 5616: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 16: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.483, train_accuracy_step=0.850, val_loss=0.467, epoch_val_accuracy=0.847, epoch_val_precision=0.886, epoch_val_rEpoch 16, global step 5967: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 17: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.357, train_accuracy_step=0.850, val_loss=0.398, epoch_val_accuracy=0.850, epoch_val_precision=0.915, epoch_val_rEpoch 17, global step 6318: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 18: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.0732, train_accuracy_step=1.000, val_loss=0.465, epoch_val_accuracy=0.838, epoch_val_precision=0.870, epoch_val_Epoch 18, global step 6669: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 19: 100%|█| 351/351 [01:01<00:00,  5.71it/s, v_num=0, train_loss_step=0.211, train_accuracy_step=0.950, val_loss=0.492, epoch_val_accuracy=0.827, epoch_val_precision=0.830, epoch_val_rEpoch 19, global step 7020: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 20: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.185, train_accuracy_step=0.900, val_loss=0.411, epoch_val_accuracy=0.842, epoch_val_precision=0.878, epoch_val_rEpoch 20, global step 7371: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 21: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.337, train_accuracy_step=0.900, val_loss=0.583, epoch_val_accuracy=0.827, epoch_val_precision=0.837, epoch_val_rEpoch 21, global step 7722: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 22: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.469, train_accuracy_step=0.850, val_loss=0.541, epoch_val_accuracy=0.832, epoch_val_precision=0.826, epoch_val_rEpoch 22, global step 8073: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 23: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.0485, train_accuracy_step=1.000, val_loss=0.574, epoch_val_accuracy=0.824, epoch_val_precision=0.809, epoch_val_Epoch 23, global step 8424: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 24: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.0765, train_accuracy_step=1.000, val_loss=0.486, epoch_val_accuracy=0.845, epoch_val_precision=0.872, epoch_val_Epoch 24, global step 8775: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 25: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.0167, train_accuracy_step=1.000, val_loss=0.643, epoch_val_accuracy=0.805, epoch_val_precision=0.783, epoch_val_Epoch 25, global step 9126: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 26: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.188, train_accuracy_step=0.950, val_loss=0.614, epoch_val_accuracy=0.840, epoch_val_precision=0.854, epoch_val_rEpoch 26, global step 9477: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 27: 100%|█| 351/351 [01:01<00:00,  5.72it/s, v_num=0, train_loss_step=0.127, train_accuracy_step=0.900, val_loss=0.641, epoch_val_accuracy=0.835, epoch_val_precision=0.840, epoch_val_rEpoch 27, global step 9828: 'epoch_val_accuracy' was not in top 1                                                                                                                             
Epoch 28: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.071, train_accuracy_step=0.950, val_loss=0.651, epoch_val_accuracy=0.839, epoch_val_precision=0.854, epoch_val_rEpoch 28, global step 10179: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 29: 100%|█| 351/351 [01:01<00:00,  5.74it/s, v_num=0, train_loss_step=0.0693, train_accuracy_step=0.950, val_loss=0.647, epoch_val_accuracy=0.839, epoch_val_precision=0.852, epoch_val_Epoch 29, global step 10530: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 30: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.089, train_accuracy_step=0.950, val_loss=0.653, epoch_val_accuracy=0.840, epoch_val_precision=0.847, epoch_val_rEpoch 30, global step 10881: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 31: 100%|█| 351/351 [01:01<00:00,  5.74it/s, v_num=0, train_loss_step=0.0436, train_accuracy_step=1.000, val_loss=0.652, epoch_val_accuracy=0.840, epoch_val_precision=0.847, epoch_val_Epoch 31, global step 11232: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 32: 100%|█| 351/351 [01:01<00:00,  5.75it/s, v_num=0, train_loss_step=0.0942, train_accuracy_step=0.950, val_loss=0.670, epoch_val_accuracy=0.840, epoch_val_precision=0.851, epoch_val_Epoch 32, global step 11583: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 33: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.0202, train_accuracy_step=1.000, val_loss=0.821, epoch_val_accuracy=0.826, epoch_val_precision=0.825, epoch_val_Epoch 33, global step 11934: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 34: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.0405, train_accuracy_step=1.000, val_loss=0.808, epoch_val_accuracy=0.843, epoch_val_precision=0.863, epoch_val_Epoch 34, global step 12285: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 35: 100%|█| 351/351 [01:01<00:00,  5.74it/s, v_num=0, train_loss_step=0.026, train_accuracy_step=1.000, val_loss=0.763, epoch_val_accuracy=0.810, epoch_val_precision=0.795, epoch_val_rEpoch 35, global step 12636: 'epoch_val_accuracy' was not in top 1                                                                                                                            
Epoch 36: 100%|█| 351/351 [01:01<00:00,  5.73it/s, v_num=0, train_loss_step=0.121, train_accuracy_step=0.950, val_loss=0.756, epoch_val_accuracy=0.832, epoch_val_precision=0.837, epoch_val_rMonitored metric epoch_val_accuracy did not improve in the last 33 records. Best score: 0.860. Signaling Trainer to stop.                                                                     
Epoch 36, global step 12987: 'epoch_val_accuracy' was not in top 1
Epoch 36: 100%|█| 351/351 [01:02<00:00,  5.63it/s, v_num=0, train_loss_step=0.121, train_accuracy_step=0.950, val_loss=0.756, epoch_val_accuracy=0.832, epoch_val_precision=0.837, epoch_val_r
--------------------------------------------------------------------------


Testing Model...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:02<00:00, 17.47it/s]Test metrics saved to: ./experiments/2025-01-08_20-39/model_results/test_metrics.csv
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:03<00:00, 13.24it/s]
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         Test metric                   DataLoader 0
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test_Accuracy               0.9586894512176514
          Test_AuPRC                0.9470933079719543
          Test_AuROC                0.9588862657546997
      Test_F-beta_score             0.9621570110321045
        Test_F1_score               0.9610214829444885
           Test_MCC                 0.9171448349952698
        Test_Precision              0.9662162065505981
         Test_Recall                0.9558823704719543
Test_Sensitivity (TP-Accuracy)      0.9558823704719543
Test_Specificity (TN-Accuracy)      0.9618902206420898
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
EOF